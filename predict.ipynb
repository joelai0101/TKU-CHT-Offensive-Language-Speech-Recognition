{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "123676e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from transformers import BertTokenizer\n",
    "import pandas as pd\n",
    "from torch import nn\n",
    "from transformers import BertModel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf913bed",
   "metadata": {},
   "source": [
    "# 預測"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f97fb93b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertClassifier(nn.Module):\n",
    "\n",
    "    def __init__(self, dropout=0.5):\n",
    "\n",
    "        super(BertClassifier, self).__init__()\n",
    "\n",
    "        self.bert = BertModel.from_pretrained('bert-base-chinese')\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.linear = nn.Linear(768, 2)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, input_id, mask):\n",
    "\n",
    "        _, pooled_output = self.bert(input_ids= input_id, attention_mask=mask,return_dict=False)\n",
    "        dropout_output = self.dropout(pooled_output)\n",
    "        linear_output = self.linear(dropout_output)\n",
    "        final_layer = self.relu(linear_output)\n",
    "\n",
    "        return final_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "43ea8d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dict_path = './models/model_bert.pth'\n",
    "model_dict = torch.load(model_dict_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b04decdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-chinese were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertClassifier(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(21128, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       "  (linear): Linear(in_features=768, out_features=2, bias=True)\n",
       "  (relu): ReLU()\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = BertClassifier()\n",
    "model.load_state_dict(model_dict['model_state_dict'])\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eaf3e736",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, text):\n",
    "    tokenizer = BertTokenizer.from_pretrained('bert-base-chinese')\n",
    "    predict_input = tokenizer(text, padding='max_length', max_length = 32, truncation=True, return_tensors=\"pt\")\n",
    "\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "    if use_cuda:\n",
    "\n",
    "        model = model.cuda()\n",
    "\n",
    "    predict_mask = predict_input['attention_mask'].to(device)\n",
    "    predict_input_id = predict_input['input_ids'].squeeze(1).to(device)\n",
    "\n",
    "    predict_output = model(predict_input_id, predict_mask)\n",
    "    #print(predict_output)\n",
    "    #print(predict_output.argmax(dim=1))\n",
    "    predict_label = predict_output.argmax(dim=1).item()\n",
    "    #print(text, predict_label)\n",
    "    return predict_label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "757116fa",
   "metadata": {},
   "source": [
    "## 舉例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "35338ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_text_1 = \"只會選舉的草包\"\n",
    "test_text_2 = \"實在有夠噁心\"\n",
    "test_text_3 = \"垃圾，在那叫什麼\"\n",
    "test_text_4 = \"希望台灣能更好\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "821447ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "只會選舉的草包 1\n"
     ]
    }
   ],
   "source": [
    "offensive_predict = predict(model, test_text_1)\n",
    "print(test_text_1, offensive_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f596840f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "實在有夠噁心 1\n"
     ]
    }
   ],
   "source": [
    "offensive_predict = predict(model, test_text_2)\n",
    "print(test_text_2, offensive_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "89a6cf2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "垃圾，在那叫什麼 1\n"
     ]
    }
   ],
   "source": [
    "offensive_predict = predict(model, test_text_3)\n",
    "print(test_text_3, offensive_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "19b5a6fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "希望台灣能更好 0\n"
     ]
    }
   ],
   "source": [
    "offensive_predict = predict(model, test_text_4)\n",
    "print(test_text_4, offensive_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60fe2530",
   "metadata": {},
   "source": [
    "## 選取資料區間進行預測"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "bb1cad3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root = './preprocessing/data.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "7a297e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(data_root)\n",
    "df = df[['sentence', 'label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "20a9869d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df = df.sample(n=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "4d979bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_sentences = sample_df['sentence'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "cbe20216",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_labels = []\n",
    "for i in predict_sentences:\n",
    "    predict_label = predict(model, i)\n",
    "    predict_labels.append(predict_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "82bd0d0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0]\n"
     ]
    }
   ],
   "source": [
    "print(predict_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f56b3a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "labelsMap = {\n",
    "    'Non-offensive':0,\n",
    "    'Offensive':1,\n",
    "          }\n",
    "\n",
    "#text_df.label = text_df.label.map(labelsMap)\n",
    "translated_predict_labels = [next(key for key, value in labelsMap.items() if value == i) for i in predict_labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a1cf4ed4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Offensive', 'Offensive', 'Offensive', 'Non-offensive', 'Non-offensive', 'Non-offensive', 'Non-offensive', 'Non-offensive', 'Non-offensive', 'Non-offensive', 'Non-offensive', 'Non-offensive', 'Non-offensive', 'Non-offensive', 'Non-offensive', 'Non-offensive', 'Non-offensive', 'Non-offensive', 'Non-offensive', 'Non-offensive', 'Non-offensive', 'Non-offensive', 'Non-offensive', 'Non-offensive', 'Non-offensive', 'Non-offensive', 'Non-offensive', 'Offensive', 'Non-offensive', 'Non-offensive', 'Offensive', 'Non-offensive', 'Non-offensive', 'Non-offensive', 'Offensive', 'Non-offensive', 'Offensive', 'Offensive', 'Offensive', 'Non-offensive', 'Non-offensive', 'Non-offensive', 'Offensive', 'Non-offensive', 'Non-offensive', 'Offensive', 'Non-offensive', 'Non-offensive', 'Offensive', 'Non-offensive', 'Non-offensive', 'Offensive', 'Non-offensive', 'Offensive', 'Non-offensive', 'Offensive', 'Non-offensive', 'Non-offensive', 'Non-offensive', 'Non-offensive', 'Non-offensive', 'Offensive', 'Non-offensive', 'Non-offensive', 'Non-offensive', 'Non-offensive', 'Non-offensive', 'Offensive', 'Non-offensive', 'Non-offensive', 'Non-offensive', 'Offensive', 'Non-offensive', 'Offensive', 'Non-offensive', 'Non-offensive', 'Non-offensive', 'Non-offensive', 'Offensive', 'Non-offensive', 'Offensive', 'Non-offensive', 'Offensive', 'Offensive', 'Non-offensive', 'Non-offensive', 'Non-offensive', 'Non-offensive', 'Non-offensive', 'Offensive', 'Offensive', 'Non-offensive', 'Non-offensive', 'Non-offensive', 'Offensive', 'Non-offensive', 'Non-offensive', 'Non-offensive', 'Offensive', 'Offensive', 'Non-offensive', 'Offensive', 'Non-offensive', 'Non-offensive', 'Offensive', 'Non-offensive', 'Offensive', 'Non-offensive', 'Non-offensive', 'Non-offensive', 'Non-offensive', 'Non-offensive', 'Offensive', 'Non-offensive', 'Offensive', 'Offensive', 'Non-offensive', 'Non-offensive', 'Offensive', 'Non-offensive', 'Non-offensive', 'Non-offensive', 'Non-offensive', 'Non-offensive', 'Non-offensive', 'Non-offensive', 'Non-offensive', 'Non-offensive', 'Non-offensive', 'Non-offensive', 'Non-offensive', 'Non-offensive', 'Non-offensive', 'Non-offensive', 'Non-offensive', 'Non-offensive', 'Offensive', 'Non-offensive', 'Non-offensive', 'Offensive', 'Non-offensive', 'Non-offensive', 'Offensive', 'Non-offensive', 'Non-offensive', 'Non-offensive', 'Offensive', 'Non-offensive', 'Non-offensive', 'Offensive', 'Non-offensive', 'Non-offensive', 'Offensive', 'Non-offensive', 'Non-offensive', 'Non-offensive', 'Non-offensive', 'Non-offensive', 'Non-offensive', 'Non-offensive', 'Offensive', 'Offensive', 'Non-offensive', 'Non-offensive', 'Non-offensive', 'Offensive', 'Non-offensive', 'Non-offensive', 'Non-offensive', 'Non-offensive', 'Non-offensive', 'Non-offensive', 'Non-offensive', 'Non-offensive', 'Non-offensive', 'Non-offensive', 'Non-offensive', 'Non-offensive', 'Non-offensive', 'Non-offensive', 'Non-offensive', 'Offensive', 'Non-offensive', 'Non-offensive', 'Non-offensive', 'Non-offensive', 'Non-offensive', 'Offensive', 'Offensive', 'Non-offensive', 'Offensive', 'Non-offensive', 'Non-offensive', 'Non-offensive', 'Non-offensive', 'Non-offensive', 'Offensive', 'Non-offensive', 'Non-offensive', 'Non-offensive', 'Non-offensive', 'Non-offensive', 'Non-offensive', 'Non-offensive', 'Non-offensive', 'Non-offensive', 'Non-offensive', 'Non-offensive', 'Offensive', 'Non-offensive', 'Non-offensive', 'Non-offensive', 'Non-offensive', 'Non-offensive', 'Non-offensive', 'Non-offensive', 'Offensive', 'Non-offensive', 'Non-offensive', 'Non-offensive', 'Non-offensive', 'Non-offensive', 'Non-offensive', 'Offensive', 'Offensive', 'Offensive', 'Non-offensive', 'Non-offensive', 'Non-offensive', 'Non-offensive', 'Non-offensive', 'Non-offensive', 'Non-offensive', 'Non-offensive', 'Non-offensive', 'Non-offensive', 'Non-offensive', 'Offensive', 'Non-offensive', 'Non-offensive', 'Non-offensive', 'Offensive', 'Non-offensive', 'Non-offensive', 'Non-offensive', 'Offensive', 'Non-offensive', 'Non-offensive', 'Non-offensive', 'Non-offensive', 'Offensive', 'Non-offensive', 'Non-offensive', 'Non-offensive', 'Non-offensive', 'Non-offensive', 'Non-offensive', 'Offensive', 'Offensive', 'Non-offensive', 'Non-offensive', 'Non-offensive', 'Offensive', 'Non-offensive', 'Non-offensive', 'Non-offensive', 'Non-offensive', 'Offensive', 'Non-offensive', 'Non-offensive', 'Non-offensive', 'Offensive', 'Offensive', 'Non-offensive', 'Non-offensive', 'Non-offensive', 'Non-offensive', 'Non-offensive', 'Non-offensive', 'Non-offensive', 'Non-offensive', 'Non-offensive', 'Non-offensive', 'Offensive', 'Non-offensive', 'Offensive', 'Non-offensive', 'Offensive', 'Non-offensive', 'Non-offensive', 'Offensive', 'Non-offensive', 'Non-offensive', 'Non-offensive', 'Non-offensive', 'Non-offensive', 'Non-offensive', 'Non-offensive', 'Offensive', 'Non-offensive']\n"
     ]
    }
   ],
   "source": [
    "print(translated_predict_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "9d83cd8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df['label'] = translated_predict_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "c7b661aa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>631</th>\n",
       "      <td>笑死</td>\n",
       "      <td>Offensive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>420</th>\n",
       "      <td>怎麼綠蟑螂超急</td>\n",
       "      <td>Offensive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3868</th>\n",
       "      <td>賣國KMT沒辦法去</td>\n",
       "      <td>Offensive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2746</th>\n",
       "      <td>你議員都黑道一起挺</td>\n",
       "      <td>Non-offensive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4609</th>\n",
       "      <td>搞不好4X早有照片等著在接駁車VIP？接駁車是勞講的東西沒幾個真的，這種讚讚讚，2024穩了...</td>\n",
       "      <td>Non-offensive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1904</th>\n",
       "      <td>很不方每天核酸，存款2099才加強版綠共阿vpn會大賣看不到好萊塢影片我不行護照不能用做核酸了</td>\n",
       "      <td>Non-offensive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3468</th>\n",
       "      <td>人就散啦zzzzz這人有可信度嗎？開啦</td>\n",
       "      <td>Non-offensive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1322</th>\n",
       "      <td>那我決定有高級業務嘴的實力寧願相信世上有鬼也不信小妳講的是哪個平行宇宙的陳疫苗要排</td>\n",
       "      <td>Non-offensive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4549</th>\n",
       "      <td>民進黨不可能認錯</td>\n",
       "      <td>Offensive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2903</th>\n",
       "      <td>傻傻的沒事亂立flag，中央表現收！！雄雄可以放心@@尾刀仔，就祈禱不會被中央直接收割</td>\n",
       "      <td>Non-offensive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               sentence          label\n",
       "631                                                  笑死      Offensive\n",
       "420                                             怎麼綠蟑螂超急      Offensive\n",
       "3868                                          賣國KMT沒辦法去      Offensive\n",
       "2746                                          你議員都黑道一起挺  Non-offensive\n",
       "4609  搞不好4X早有照片等著在接駁車VIP？接駁車是勞講的東西沒幾個真的，這種讚讚讚，2024穩了...  Non-offensive\n",
       "...                                                 ...            ...\n",
       "1904    很不方每天核酸，存款2099才加強版綠共阿vpn會大賣看不到好萊塢影片我不行護照不能用做核酸了  Non-offensive\n",
       "3468                                人就散啦zzzzz這人有可信度嗎？開啦  Non-offensive\n",
       "1322          那我決定有高級業務嘴的實力寧願相信世上有鬼也不信小妳講的是哪個平行宇宙的陳疫苗要排  Non-offensive\n",
       "4549                                           民進黨不可能認錯      Offensive\n",
       "2903        傻傻的沒事亂立flag，中央表現收！！雄雄可以放心@@尾刀仔，就祈禱不會被中央直接收割  Non-offensive\n",
       "\n",
       "[300 rows x 2 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "0ebaccd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df.to_csv('predict_sample_data.csv', encoding='utf_8_sig')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69f74359",
   "metadata": {},
   "source": [
    "# 對 predict_sample_data 進行人工修正"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21192bfa",
   "metadata": {},
   "source": [
    "# 加入到訓練資料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "6f2aa046",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data_root = './preprocessing/new_data.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "5929b1e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = pd.read_csv(new_data_root)\n",
    "new_df = new_df[['sentence', 'label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "3a891cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = pd.merge(new_df, sample_df, on=None, how='outer', indicator=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "8be7d6af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>希望台灣會更好大推這篇！！推</td>\n",
       "      <td>Non-offensive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>下面沒人要跟土城找安囉</td>\n",
       "      <td>Non-offensive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0每個小瑕疵看起來都很細微過高屏溪都殺人無罪了</td>\n",
       "      <td>Non-offensive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>淪落到連打一個教嗚嗚嗚，好可憐，都是柯P霸凌慣犯阿苗怎麼不幫幫你的苗粉快去死吧！政治蟑螂直接...</td>\n",
       "      <td>Non-offensive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>但是司法你以綠能你不能啦要就全國一起玩台南感覺更哇，把新竹選民當白癡耍是第一天認識民進黨？還沒就職</td>\n",
       "      <td>Non-offensive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1191</th>\n",
       "      <td>很不方每天核酸，存款2099才加強版綠共阿vpn會大賣看不到好萊塢影片我不行護照不能用做核酸了</td>\n",
       "      <td>Non-offensive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1192</th>\n",
       "      <td>人就散啦zzzzz這人有可信度嗎？開啦</td>\n",
       "      <td>Non-offensive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1193</th>\n",
       "      <td>那我決定有高級業務嘴的實力寧願相信世上有鬼也不信小妳講的是哪個平行宇宙的陳疫苗要排</td>\n",
       "      <td>Non-offensive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1194</th>\n",
       "      <td>民進黨不可能認錯</td>\n",
       "      <td>Offensive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1195</th>\n",
       "      <td>傻傻的沒事亂立flag，中央表現收！！雄雄可以放心@@尾刀仔，就祈禱不會被中央直接收割</td>\n",
       "      <td>Non-offensive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1196 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               sentence          label\n",
       "0                                        希望台灣會更好大推這篇！！推  Non-offensive\n",
       "1                                           下面沒人要跟土城找安囉  Non-offensive\n",
       "2                               0每個小瑕疵看起來都很細微過高屏溪都殺人無罪了  Non-offensive\n",
       "3     淪落到連打一個教嗚嗚嗚，好可憐，都是柯P霸凌慣犯阿苗怎麼不幫幫你的苗粉快去死吧！政治蟑螂直接...  Non-offensive\n",
       "4     但是司法你以綠能你不能啦要就全國一起玩台南感覺更哇，把新竹選民當白癡耍是第一天認識民進黨？還沒就職  Non-offensive\n",
       "...                                                 ...            ...\n",
       "1191    很不方每天核酸，存款2099才加強版綠共阿vpn會大賣看不到好萊塢影片我不行護照不能用做核酸了  Non-offensive\n",
       "1192                                人就散啦zzzzz這人有可信度嗎？開啦  Non-offensive\n",
       "1193          那我決定有高級業務嘴的實力寧願相信世上有鬼也不信小妳講的是哪個平行宇宙的陳疫苗要排  Non-offensive\n",
       "1194                                           民進黨不可能認錯      Offensive\n",
       "1195        傻傻的沒事亂立flag，中央表現收！！雄雄可以放心@@尾刀仔，就祈禱不會被中央直接收割  Non-offensive\n",
       "\n",
       "[1196 rows x 2 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c555ff86",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.to_csv('./preprocessing/new_data.csv', encoding='utf_8_sig')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
